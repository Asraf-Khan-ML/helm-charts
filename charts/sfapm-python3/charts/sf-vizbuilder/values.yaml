# Default values for sfapm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# set to true to enable debug logs on
# apm and vizbuilder
enableDebug: false
archiverEnabled: true
nameOverride: ""
fullnameOverride: ""
imagePullSecrets: []

sidecarLogger:
  enabled: true

  image:
    pullPolicy: Always

  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 50m
      memory: 50Mi

vizbuilder:

  pgBouncer:
    enabled: false
    dbHost: ""
    dbPort: ""
    dbUser: ""
    dbPassword: ""

  replicaCount: 2

  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 3
    # Below values are based on requests.
    # Hence value > 100 needs to be calculated based on set limits
    # Below values are calculated such that (limit / request) * 80 -> for 80% target utilization
    targetCPUUtilizationPercentage: 8000
    targetMemoryUtilizationPercentage: 240

  image:
    repository: snappyflowml/sfapm-vizbuilder
    tag: 4.0.219-python3
    pullPolicy: IfNotPresent

  resources:
    limits:
      cpu: 1000m
      memory: 768Mi
    requests:
      cpu: 10m
      memory: 256Mi

  service:
    type: ClusterIP
    port: 8000

vizbuilder_celery:
  env:
    C_FORCE_ROOT: true
    CELERY_OPTS: "-O fair --max-tasks-per-child 20 -P gevent"
    MAXIMUM_RUNNING_TASKS: 10

  beat:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 10m
        memory: 100Mi
    command: "celery -A vizbuilder beat -l $LOG_LEVEL"

  alert:
    resources:
      limits:
        cpu: 1000m
        memory: 768Mi
      requests:
        cpu: 10m
        memory: 100Mi
    replicaCount: 3
    command: "celery -A vizbuilder worker -l $LOG_LEVEL -Q alert -c $MAXIMUM_RUNNING_TASKS $CELERY_OPTS & celery -A vizbuilder flower --address=localhost --port=5566"

    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 5
      scaleUpPeriod: 30
      scaleDownPeriod: 60
    
    podAnnotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "2112"
      prometheus.io/scrape: "true"
    
    terminationGracePeriodSeconds: 300
    
    celeryAlertPrometheusExporter:
      image:
        pullPolicy: Always
      metricsInterval: 3
      resources:
        requests:
          cpu: 100m
          memory: 200Mi

  logops:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 10m
        memory: 100Mi
    replicaCount: 1
    command: "celery -A vizbuilder worker -l $LOG_LEVEL -Q logops -c10 $CELERY_OPTS"

  signature:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 10m
        memory: 100Mi
    replicaCount: 1
    command: "celery -A vizbuilder worker -l $LOG_LEVEL -Q signature -c10 $CELERY_OPTS"

  provisiontemplate:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 10m
        memory: 100Mi
    replicaCount: 1
    command: "celery -A vizbuilder worker -l $LOG_LEVEL -Q provisiontemplate -c1 $CELERY_OPTS"

# set this to true/True if using pg bouncer
disable_server_side_cursors: false

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  # The names of the image pull secrets to be attached to this service account
  imagePullSecrets: []
  # disable mounting sa token inside pods
  automountServiceAccountToken: false

podAnnotations:
  prometheus.io/scrape: "false"
  
nodeSelector: {}

tolerations: []

affinity: {}

cloud:
  aws:
    enable: true
  gcs:
    enable: false
    # Set all of the below entities when Google-Service-Account is being used. Recommended approach unless K8s is running outside GCP (K8s outside GCP flow which will use JSON service-account-keys is not yet implemented)
    use_google_service_account: true
    service_account: "XXXX-compute@developer.gserviceaccount.com OR XXXX@XXXX.iam.gserviceaccount.com"
    region: us-west1
    zone: us-west1-c
  datacenter:
    enable: false

postgresql:
  # enabled true deploys postgresql as statefull set on the same cluster
  enabled: true

  # if enabled false, chart will connect to external database
  # create two data bases with names snappyflow and vizbuilder
  # create a user and grant access to database snappyflow and vizbuilder
  # provide external section if enabled is false

  external:
    dbHost: ""
    dbPort: ""
    dbUser: ""
    dbPassword: ""

  image:
    repository: postgres
    pullPolicy: IfNotPresent
    tag: "9.6"

  # when local postgresql is enabled below values are used to configure database
  rootPassword: postgres
  rootUser: postgres
  multidb: snappyflow;vizbuilder;commands;elasticsearch_manager
  multidbUser: snappyflow
  multidbUserPassord: maplelabs

redis:
  image:
    repository: redis
    pullPolicy: IfNotPresent
    tag: "5.0"
	
securityContext:
  {}

pprof:
  service:
    type: ClusterIP
    port: 8090

sfapm:
  service:
    type: ClusterIP
    port: 8000
	
esmanager:
  service:
    type: ClusterIP
    port: 8000

global:
  sfappname: sf-portal-app
  sfprojectname: snappyflow-app
  sfappname_key: snappyflow/appname
  sfprojectname_key: snappyflow/projectname
  nginx_geo_info_collection: true
  nginx_ua_parsing: true
  enable_sftrace: false
  key: ""

  sfNodeManager:
    enabled: false
    priorityClassName: sf-critical-pod
  sfScheduler:
    enabled: false
    schedulerName: sf-scheduler